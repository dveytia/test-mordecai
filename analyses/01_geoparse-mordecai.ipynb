{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a370953a-70c3-4b93-bb2f-512ec230a9bf",
   "metadata": {},
   "source": [
    "# 01 Geoparsing using mordecai\n",
    "\n",
    "Analysis reads in title and abstract data from file, runs mordecai and returns a data frame with unique locations for each entry\n",
    "\n",
    "*Note* This code only works when running on the envname kernel, which was created from the mordecai_env_XXXXXX.yml file (details of modules also in requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280657f-ba54-41e5-8f02-a870a742962e",
   "metadata": {},
   "source": [
    "## Set up: import modules and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a9d609-675e-498a-8c28-457d1504fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:16:25.959933: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 14:16:26.195908: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-27 14:16:26.242677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:26.242709: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-27 14:16:27.317341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:27.317401: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:27.317408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models path: /home/dveytia/.local/lib/python3.8/site-packages/mordecai/models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:16:40.560124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:40.560414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:40.560457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:40.585110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:40.585188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:40.585240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-27 14:16:40.585256: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-27 14:16:40.587124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "GET http://localhost:9200/geonames/_count [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dveytia/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 114, in perform_request\n",
      "    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/usr/lib/python3/dist-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 171, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f46f4b14040>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "GET http://localhost:9200/geonames/_count [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dveytia/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 114, in perform_request\n",
      "    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/usr/lib/python3/dist-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 171, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f46f4b14220>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "GET http://localhost:9200/geonames/_count [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dveytia/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 114, in perform_request\n",
      "    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/usr/lib/python3/dist-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 171, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f46f4b14430>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "GET http://localhost:9200/geonames/_count [status:N/A request:0.001s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 84, in create_connection\n",
      "    raise err\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 74, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dveytia/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\", line 114, in perform_request\n",
      "    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 376, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/usr/lib/python3/dist-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 387, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 187, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 171, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f46f4b14460>: Failed to establish a new connection: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:159\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:84\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:74\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 74\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py:114\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore)\u001b[0m\n\u001b[1;32m    112\u001b[0m     method \u001b[38;5;241m=\u001b[39m method\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:719\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    717\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 719\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/retry.py:376\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m error:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# Disabled, indicate to re-raise the error.\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/six.py:703\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:665\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:387\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# Reset the timeout for the recv() on the socket\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m \n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:187\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 187\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:171\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f46f4b14460>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mordecai/geoparse.py:71\u001b[0m, in \u001b[0;36mGeoparser.__init__\u001b[0;34m(self, nlp, es_hosts, es_port, es_ssl, es_auth, verbose, country_threshold, threads, progress, training, models_path, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# https://www.reddit.com/r/Python/comments/3a2erd/exception_catch_not_catching_everything/\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# with nostderr():\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch_dsl/search.py:583\u001b[0m, in \u001b[0;36mSearch.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# TODO: failed shards detection\u001b[39;00m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_doc_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_params\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/client/utils.py:73\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         params[p] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(p)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/client/__init__.py:1122\u001b[0m, in \u001b[0;36mElasticsearch.count\u001b[0;34m(self, index, doc_type, body, params)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_all\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_make_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/transport.py:312\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, params, body)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     status, headers, data \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TransportError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py:123\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionTimeout(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIMEOUT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e), e)\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e), e)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# raise errors based on http status codes, let the client handle those if needed\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ConnectionError(<urllib3.connection.HTTPConnection object at 0x7f46f4b14460>: Failed to establish a new connection: [Errno 111] Connection refused) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x7f46f4b14460>: Failed to establish a new connection: [Errno 111] Connection refused)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmordecai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Geoparser\n\u001b[0;32m----> 3\u001b[0m geo \u001b[38;5;241m=\u001b[39m \u001b[43mGeoparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/mordecai/geoparse.py:73\u001b[0m, in \u001b[0;36mGeoparser.__init__\u001b[0;34m(self, nlp, es_hosts, es_port, es_ssl, es_auth, verbose, country_threshold, threads, progress, training, models_path, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCould not establish contact with Elasticsearch at \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m on port \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124mAre you sure it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms running?\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124mMordecai needs access to the Geonames/Elasticsearch gazetteer to function.\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124mSee https://github.com/openeventdata/mordecai#installation-and-requirements\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124mfor instructions on setting up Geonames/Elasticsearch\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(es_hosts, es_port))\n\u001b[1;32m     78\u001b[0m         es_date \u001b[38;5;241m=\u001b[39m utilities\u001b[38;5;241m.\u001b[39mcheck_geonames_date(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn)\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'IndexError'>, IndexError('tuple index out of range'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:2068\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2065\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2068\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2070\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py:550\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    544\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    545\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    547\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    551\u001b[0m }\n\u001b[1;32m    553\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/exceptions.py:69\u001b[0m, in \u001b[0;36mConnectionError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnectionError(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) caused by: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/exceptions.py:44\u001b[0m, in \u001b[0;36mTransportError.error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" A string error message. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "## Set up mordecai geoparser\n",
    "from mordecai import Geoparser\n",
    "geo = Geoparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d3843a-5ab8-4b3d-841a-e96a146edbd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test mordecai\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgeo\u001b[49m\u001b[38;5;241m.\u001b[39mgeoparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI traveled from Oxford to Ottawa.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geo' is not defined"
     ]
    }
   ],
   "source": [
    "# test mordecai\n",
    "geo.geoparse(\"I traveled from Oxford to Ottawa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4347921-0829-42e3-9f8b-7d9bebaf84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import other modules\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89551360-a972-43dc-9f00-deee2e9bdf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in test geoparsing data\n",
    "#df = pd.read_csv('C:\\\\Users\\\\deviv\\\\Python-working-folder\\\\test-mordecai\\\\data\\\\raw-data\\\\test-geocode-text.csv')\n",
    "\n",
    "# combine title and abstract text into one variable\n",
    "#df['text'] = df['title'] + df['abstract']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b9c63bc-7ea5-4e08-bfd9-3c0600876dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>relevance_mean</th>\n",
       "      <th>relevance_std</th>\n",
       "      <th>relevance_lower</th>\n",
       "      <th>relevance_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353882</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53630</td>\n",
       "      <td>0.134056</td>\n",
       "      <td>0.226679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48146</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.017286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370725</td>\n",
       "      <td>0.193188</td>\n",
       "      <td>0.188347</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.381535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161800</td>\n",
       "      <td>0.092730</td>\n",
       "      <td>0.201549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_id  relevance_mean  relevance_std  relevance_lower  \\\n",
       "0       353882        0.025407       0.028486         0.000000   \n",
       "1        53630        0.134056       0.226679         0.000000   \n",
       "2        48146        0.009870       0.007417         0.002453   \n",
       "3       370725        0.193188       0.188347         0.004841   \n",
       "4       161800        0.092730       0.201549         0.000000   \n",
       "\n",
       "   relevance_upper  \n",
       "0         0.053893  \n",
       "1         0.360735  \n",
       "2         0.017286  \n",
       "3         0.381535  \n",
       "4         0.294279  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in the relevance predictions\n",
    "relPredCon = sqlite3.connect(\"\\\\\".join([\"C:\",\"Users\",\"deviv\",\"Python-working-folder\",\"test-mordecai\",\"data\",\"raw-data\",\"sql-databases\",\"relevance-predictions.sqlite\"]))\n",
    "\n",
    "relPred_df = pd.read_sql_query(\"SELECT * from predRel\", relPredCon)\n",
    "\n",
    "# if needed, check table names:\n",
    "#cursor = relPredCon.cursor()\n",
    "#cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#print(cursor.fetchall())\n",
    "\n",
    "# transform analysis_id column\n",
    "relPred_df.analysis_id = relPred_df.analysis_id.astype(int)\n",
    "\n",
    "relPredCon.close()\n",
    "relPred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00132351-cf80-4c4f-a538-09807a108682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>duplicate_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296164</td>\n",
       "      <td>1913.2039</td>\n",
       "      <td>On the Precipitation of Calcium Carbonate in t...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296163</td>\n",
       "      <td>1917.2039</td>\n",
       "      <td>Climatic change and agricultural exhaustion as...</td>\n",
       "      <td>I. Decline in Roman agriculture, 173. Contrast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384729</td>\n",
       "      <td>1917.2040</td>\n",
       "      <td>Tidal energy dissipation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384728</td>\n",
       "      <td>1920.2039</td>\n",
       "      <td>Tidal power</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384727</td>\n",
       "      <td>1921.2039</td>\n",
       "      <td>Tidal power [3]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_id duplicate_id  \\\n",
       "0       296164    1913.2039   \n",
       "1       296163    1917.2039   \n",
       "2       384729    1917.2040   \n",
       "3       384728    1920.2039   \n",
       "4       384727    1921.2039   \n",
       "\n",
       "                                               title  \\\n",
       "0  On the Precipitation of Calcium Carbonate in t...   \n",
       "1  Climatic change and agricultural exhaustion as...   \n",
       "2                           Tidal energy dissipation   \n",
       "3                                        Tidal power   \n",
       "4                                    Tidal power [3]   \n",
       "\n",
       "                                            abstract  \n",
       "0                                               None  \n",
       "1  I. Decline in Roman agriculture, 173. Contrast...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in the metadata for all the unique references\n",
    "uniqueRefsCon = sqlite3.connect(\"\\\\\".join([\"C:\",\"Users\",\"deviv\",\"Python-working-folder\",\"test-mordecai\",\"data\",\"raw-data\",\"sql-databases\",\"unique-refs_v2.sqlite\"]))\n",
    "\n",
    "## add relevance predictions as a table to the new database\n",
    "#relPred_df.to_sql(\"predRel\", uniqueRefsCon, if_exists=\"replace\")\n",
    "\n",
    "# print \n",
    "uniqueRefs_df = pd.read_sql_query(\"SELECT analysis_id, duplicate_id, title, abstract FROM uniquerefs\", uniqueRefsCon)\n",
    "\n",
    "# transform analysis_id column\n",
    "uniqueRefs_df.analysis_id = uniqueRefs_df.analysis_id.astype(int)\n",
    "\n",
    "## close connections\n",
    "uniqueRefsCon.close()\n",
    "\n",
    "uniqueRefs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9939762e-91e7-4420-b3ad-40c680a2ad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269481, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueRefs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1374e096-2c13-4518-bc8e-1ac85117104d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73928"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## subset relevance predctions to >= 0.5\n",
    "relPred_df = relPred_df[0.5 <= relPred_df['relevance_mean']]\n",
    "len(relPred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a98df418-9a35-4605-90a3-a7ecfd5d6f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_mean</th>\n",
       "      <th>relevance_std</th>\n",
       "      <th>relevance_lower</th>\n",
       "      <th>relevance_upper</th>\n",
       "      <th>duplicate_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230304</th>\n",
       "      <td>0.987904</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.982894</td>\n",
       "      <td>0.992913</td>\n",
       "      <td>2021.19382</td>\n",
       "      <td>Tidal energy site characterisation in a large ...</td>\n",
       "      <td>Banks Strait is a 15 km wide tidal channel in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311856</th>\n",
       "      <td>0.924882</td>\n",
       "      <td>0.172907</td>\n",
       "      <td>0.751975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.20552</td>\n",
       "      <td>Integrated production system modelling and opt...</td>\n",
       "      <td>Objective/Scope: Applicability of Enhanced Oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354126</th>\n",
       "      <td>0.967163</td>\n",
       "      <td>0.024341</td>\n",
       "      <td>0.942821</td>\n",
       "      <td>0.991504</td>\n",
       "      <td>2011.10628</td>\n",
       "      <td>RINA, Royal Institution of Naval Architects - ...</td>\n",
       "      <td>The proceedings contain 14 papers. The topics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39779</th>\n",
       "      <td>0.625630</td>\n",
       "      <td>0.303433</td>\n",
       "      <td>0.322197</td>\n",
       "      <td>0.929063</td>\n",
       "      <td>2014.2024</td>\n",
       "      <td>Population health in the Anthropocene: Gains, ...</td>\n",
       "      <td>The health of human populations, measured by l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61009</th>\n",
       "      <td>0.989180</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.993422</td>\n",
       "      <td>2016.3747</td>\n",
       "      <td>Seagrass, mangrove and saltmarsh sedimentary c...</td>\n",
       "      <td>Coastal vegetation (seagrass, mangrove and sal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             relevance_mean  relevance_std  relevance_lower  relevance_upper  \\\n",
       "analysis_id                                                                    \n",
       "230304             0.987904       0.005010         0.982894         0.992913   \n",
       "311856             0.924882       0.172907         0.751975         1.000000   \n",
       "354126             0.967163       0.024341         0.942821         0.991504   \n",
       "39779              0.625630       0.303433         0.322197         0.929063   \n",
       "61009              0.989180       0.004243         0.984937         0.993422   \n",
       "\n",
       "            duplicate_id                                              title  \\\n",
       "analysis_id                                                                   \n",
       "230304        2021.19382  Tidal energy site characterisation in a large ...   \n",
       "311856        2020.20552  Integrated production system modelling and opt...   \n",
       "354126        2011.10628  RINA, Royal Institution of Naval Architects - ...   \n",
       "39779          2014.2024  Population health in the Anthropocene: Gains, ...   \n",
       "61009          2016.3747  Seagrass, mangrove and saltmarsh sedimentary c...   \n",
       "\n",
       "                                                      abstract  \n",
       "analysis_id                                                     \n",
       "230304       Banks Strait is a 15 km wide tidal channel in ...  \n",
       "311856       Objective/Scope: Applicability of Enhanced Oil...  \n",
       "354126       The proceedings contain 14 papers. The topics ...  \n",
       "39779        The health of human populations, measured by l...  \n",
       "61009        Coastal vegetation (seagrass, mangrove and sal...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## JOIN the relevance predictions with the text data\n",
    "df = relPred_df.set_index('analysis_id').join(uniqueRefs_df.set_index('analysis_id'), how = \"left\", lsuffix = \"_rel\", rsuffix = \"_refs\")\n",
    "#df = relPred_df.join(uniqueRefs_df, on=\"analysis_id\", how = \"left\", lsuffix = \"_rel\", rsuffix = \"_refs\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cdac10b-cff4-4a47-9884-94928346ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73928, 7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # also get the dimensions -- for some reason I don't have matches for all the relevance predictions 36477 as opposed to 73928??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cda000af-e5d6-4bc2-8f70-ba0cea4e9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create another column with title and abstract combined to Geoparse\n",
    "df['text'] = df['title'] + df['abstract']\n",
    "\n",
    "# replace \"the United States\" with \"United States\" to avoid returning the virgin islands\n",
    "# the (?i) means it is case insensitive\n",
    "df['text'] = df.text.replace(\"(?i)the (?i)United (?i)States\", \"United States\", regex=True) \n",
    "\n",
    "## alternte, but both ways work\n",
    "# df['text'] = df['text'].str.replace(\"the United States\", \"United States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ed5f3-e39e-4303-8281-99031abda2a2",
   "metadata": {},
   "source": [
    "## Analysis: Geoparse data and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915ca06-684a-4b1a-ae29-1132220d3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geoparse the text and add results as a new column \"geoparse\"\n",
    "df[\"geoparse\"] = [geo.geoparse(x) for x in df[\"text\"].astype('str')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3376c37-2968-4672-97d6-b32318cf3a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0             int64\n",
      "analysis_id            int64\n",
      "duplicate_id         float64\n",
      "title                 object\n",
      "abstract              object\n",
      "text                  object\n",
      "word                  object\n",
      "spans                 object\n",
      "country_predicted     object\n",
      "country_conf         float32\n",
      "admin1                object\n",
      "lat                  float64\n",
      "lon                  float64\n",
      "country_code3         object\n",
      "geonameid             object\n",
      "place_name            object\n",
      "feature_class         object\n",
      "feature_code          object\n",
      "0                    float64\n",
      "dtype: object\n",
      "   Unnamed: 0  analysis_id  duplicate_id  \\\n",
      "1           2        77239     2004.2448   \n",
      "3           4       141394     2017.7856   \n",
      "3           4       141394     2017.7856   \n",
      "3           4       141394     2017.7856   \n",
      "4           5       172949     2012.3571   \n",
      "\n",
      "                                               title  \\\n",
      "1  Organochlorine contaminants in sea turtles: Co...   \n",
      "3  New resource for population genetics studies o...   \n",
      "3  New resource for population genetics studies o...   \n",
      "3  New resource for population genetics studies o...   \n",
      "4  Long-term trends of coral imports into the Uni...   \n",
      "\n",
      "                                            abstract  \\\n",
      "1  Monitoring toxic organochlorine (OC) compounds...   \n",
      "3  The Australasian fucoid, Hormosira banksii, co...   \n",
      "3  The Australasian fucoid, Hormosira banksii, co...   \n",
      "3  The Australasian fucoid, Hormosira banksii, co...   \n",
      "4  The international trade in corals used to be p...   \n",
      "\n",
      "                                                text             word  \\\n",
      "1  Organochlorine contaminants in sea turtles: Co...             Kemp   \n",
      "3  New resource for population genetics studies o...  New South Wales   \n",
      "3  New resource for population genetics studies o...        Australia   \n",
      "3  New resource for population genetics studies o...   Hardy-Weinberg   \n",
      "4  Long-term trends of coral imports into the Uni...    United States   \n",
      "\n",
      "                            spans country_predicted  country_conf  \\\n",
      "1    [{'start': 845, 'end': 849}]               USA      0.879922   \n",
      "3    [{'start': 856, 'end': 871}]               AUS      0.906452   \n",
      "3    [{'start': 873, 'end': 882}]               AUS      0.951695   \n",
      "3  [{'start': 1146, 'end': 1160}]               USA      0.852964   \n",
      "4      [{'start': 43, 'end': 56}]               VIR      0.879922   \n",
      "\n",
      "            admin1       lat        lon country_code3 geonameid  \\\n",
      "1            Texas  32.44264  -96.22998           USA   4702914   \n",
      "3  New South Wales -33.00000  146.00000           AUS   2155400   \n",
      "3               NA -25.00000  135.00000           AUS   2077456   \n",
      "3     Pennsylvania  41.40639  -75.65667           USA   7127434   \n",
      "4               NA  18.34829  -64.98348           VIR   4796775   \n",
      "\n",
      "                                     place_name feature_class feature_code   0  \n",
      "1                                          Kemp             P          PPL NaN  \n",
      "3                      State of New South Wales             A         ADM1 NaN  \n",
      "3                     Commonwealth of Australia             A         PCLI NaN  \n",
      "3  Harry and Jeanette Weinberg Memorial Library             S         LIBR NaN  \n",
      "4           Virgin Islands of the United States             A         PCLD NaN  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>duplicate_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>word</th>\n",
       "      <th>spans</th>\n",
       "      <th>country_predicted</th>\n",
       "      <th>country_conf</th>\n",
       "      <th>admin1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>country_code3</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>place_name</th>\n",
       "      <th>feature_class</th>\n",
       "      <th>feature_code</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>77239</td>\n",
       "      <td>2004.2448</td>\n",
       "      <td>Organochlorine contaminants in sea turtles: Co...</td>\n",
       "      <td>Monitoring toxic organochlorine (OC) compounds...</td>\n",
       "      <td>Organochlorine contaminants in sea turtles: Co...</td>\n",
       "      <td>Kemp</td>\n",
       "      <td>[{'start': 845, 'end': 849}]</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.879922</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.44264</td>\n",
       "      <td>-96.22998</td>\n",
       "      <td>USA</td>\n",
       "      <td>4702914</td>\n",
       "      <td>Kemp</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>141394</td>\n",
       "      <td>2017.7856</td>\n",
       "      <td>New resource for population genetics studies o...</td>\n",
       "      <td>The Australasian fucoid, Hormosira banksii, co...</td>\n",
       "      <td>New resource for population genetics studies o...</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>[{'start': 856, 'end': 871}]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0.906452</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>-33.00000</td>\n",
       "      <td>146.00000</td>\n",
       "      <td>AUS</td>\n",
       "      <td>2155400</td>\n",
       "      <td>State of New South Wales</td>\n",
       "      <td>A</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>141394</td>\n",
       "      <td>2017.7856</td>\n",
       "      <td>New resource for population genetics studies o...</td>\n",
       "      <td>The Australasian fucoid, Hormosira banksii, co...</td>\n",
       "      <td>New resource for population genetics studies o...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>[{'start': 873, 'end': 882}]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0.951695</td>\n",
       "      <td>NA</td>\n",
       "      <td>-25.00000</td>\n",
       "      <td>135.00000</td>\n",
       "      <td>AUS</td>\n",
       "      <td>2077456</td>\n",
       "      <td>Commonwealth of Australia</td>\n",
       "      <td>A</td>\n",
       "      <td>PCLI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>141394</td>\n",
       "      <td>2017.7856</td>\n",
       "      <td>New resource for population genetics studies o...</td>\n",
       "      <td>The Australasian fucoid, Hormosira banksii, co...</td>\n",
       "      <td>New resource for population genetics studies o...</td>\n",
       "      <td>Hardy-Weinberg</td>\n",
       "      <td>[{'start': 1146, 'end': 1160}]</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.852964</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>41.40639</td>\n",
       "      <td>-75.65667</td>\n",
       "      <td>USA</td>\n",
       "      <td>7127434</td>\n",
       "      <td>Harry and Jeanette Weinberg Memorial Library</td>\n",
       "      <td>S</td>\n",
       "      <td>LIBR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>172949</td>\n",
       "      <td>2012.3571</td>\n",
       "      <td>Long-term trends of coral imports into the Uni...</td>\n",
       "      <td>The international trade in corals used to be p...</td>\n",
       "      <td>Long-term trends of coral imports into the Uni...</td>\n",
       "      <td>United States</td>\n",
       "      <td>[{'start': 43, 'end': 56}]</td>\n",
       "      <td>VIR</td>\n",
       "      <td>0.879922</td>\n",
       "      <td>NA</td>\n",
       "      <td>18.34829</td>\n",
       "      <td>-64.98348</td>\n",
       "      <td>VIR</td>\n",
       "      <td>4796775</td>\n",
       "      <td>Virgin Islands of the United States</td>\n",
       "      <td>A</td>\n",
       "      <td>PCLD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  analysis_id  duplicate_id  \\\n",
       "1           2        77239     2004.2448   \n",
       "3           4       141394     2017.7856   \n",
       "3           4       141394     2017.7856   \n",
       "3           4       141394     2017.7856   \n",
       "4           5       172949     2012.3571   \n",
       "\n",
       "                                               title  \\\n",
       "1  Organochlorine contaminants in sea turtles: Co...   \n",
       "3  New resource for population genetics studies o...   \n",
       "3  New resource for population genetics studies o...   \n",
       "3  New resource for population genetics studies o...   \n",
       "4  Long-term trends of coral imports into the Uni...   \n",
       "\n",
       "                                            abstract  \\\n",
       "1  Monitoring toxic organochlorine (OC) compounds...   \n",
       "3  The Australasian fucoid, Hormosira banksii, co...   \n",
       "3  The Australasian fucoid, Hormosira banksii, co...   \n",
       "3  The Australasian fucoid, Hormosira banksii, co...   \n",
       "4  The international trade in corals used to be p...   \n",
       "\n",
       "                                                text             word  \\\n",
       "1  Organochlorine contaminants in sea turtles: Co...             Kemp   \n",
       "3  New resource for population genetics studies o...  New South Wales   \n",
       "3  New resource for population genetics studies o...        Australia   \n",
       "3  New resource for population genetics studies o...   Hardy-Weinberg   \n",
       "4  Long-term trends of coral imports into the Uni...    United States   \n",
       "\n",
       "                            spans country_predicted  country_conf  \\\n",
       "1    [{'start': 845, 'end': 849}]               USA      0.879922   \n",
       "3    [{'start': 856, 'end': 871}]               AUS      0.906452   \n",
       "3    [{'start': 873, 'end': 882}]               AUS      0.951695   \n",
       "3  [{'start': 1146, 'end': 1160}]               USA      0.852964   \n",
       "4      [{'start': 43, 'end': 56}]               VIR      0.879922   \n",
       "\n",
       "            admin1       lat        lon country_code3 geonameid  \\\n",
       "1            Texas  32.44264  -96.22998           USA   4702914   \n",
       "3  New South Wales -33.00000  146.00000           AUS   2155400   \n",
       "3               NA -25.00000  135.00000           AUS   2077456   \n",
       "3     Pennsylvania  41.40639  -75.65667           USA   7127434   \n",
       "4               NA  18.34829  -64.98348           VIR   4796775   \n",
       "\n",
       "                                     place_name feature_class feature_code   0  \n",
       "1                                          Kemp             P          PPL NaN  \n",
       "3                      State of New South Wales             A         ADM1 NaN  \n",
       "3                     Commonwealth of Australia             A         PCLI NaN  \n",
       "3  Harry and Jeanette Weinberg Memorial Library             S         LIBR NaN  \n",
       "4           Virgin Islands of the United States             A         PCLD NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Format dataframe\n",
    "\n",
    "# create new formatted dataframe: df_clean\n",
    "def flat_df(df):\n",
    "    df_geo = df[df[\"geoparse\"].str.len() != 0] #subset where geoparse string is not empty\n",
    "    df_geo = df_geo.explode('geoparse') #Transforms each element of a list to a row and replicates index and all other columns. When more than one place name appears it creates more than one row.\n",
    "    df_geo = pd.concat([df_geo.drop(['geoparse'], axis=1), df_geo['geoparse'].apply(pd.Series)], axis=1) #Extract from dic\n",
    "    df_geo = pd.concat([df_geo.drop(['geo'], axis=1), df_geo['geo'].apply(pd.Series)], axis=1)\n",
    "    df_geo = df_geo[df_geo['lat'].notnull()] #Removing empty latitude rows\n",
    "    df_geo.lat = df_geo.lat.astype(float) #Transforms to float\n",
    "    df_geo.lon =df_geo.lon.astype(float) #Transforms to float\n",
    "    return df_geo\n",
    "    \n",
    "df_clean = flat_df(df)\n",
    "print(df_clean.dtypes)\n",
    "print(df_clean[0:5])\n",
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626895ed-6962-4f91-b190-036aa9b56afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Save as a .csv\n",
    "df_clean.to_csv('C:\\\\Users\\\\deviv\\\\Python-working-folder\\\\test-mordecai\\\\outputs\\\\geoparsed-records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95fb07-8791-4216-9f41-478f64157e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save as an sqlite database\n",
    "database = 'C:\\\\Users\\\\deviv\\\\Python-working-folder\\\\test-mordecai\\\\outputs\\\\geoparsed-records.sqlite'\n",
    "conn = sqlite3.connect(database)\n",
    "df_clean.to_sql(\"geoparsed-records\", con=conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mordecai_env_3.8",
   "language": "python",
   "name": "mordecai_env_3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
