{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4660450e-0bde-4aaf-8dbd-282317b64b4b",
   "metadata": {},
   "source": [
    "# 02 Gridding locations\n",
    "\n",
    "Analysis reads in locations identified for publications, de-duplicates locations by publication, identifies shapefiles from natural earth for locations, and then bin the shapefiles to the grid. If no shapefile is found, then the location is mapped to the grid cell which covers the centroid of the location. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8d3fc-b5cd-4055-932d-b4867c3d09e1",
   "metadata": {},
   "source": [
    "*Note to Vicky*\n",
    "Also, it would be great to store the area of each polygon before binning and store it in a separate data frame so we can examine the spatial scale of different publications. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fab5d00-1555-4b48-a153-12af51edc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load our location data and drop any duplicated places within documents\n",
    "import pandas as pd\n",
    "import shapely.vectorized\n",
    "from global_land_mask import globe\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa0f993-7081-4743-a9d5-eaf20ed71f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup parameters\n",
    "gridRes = 2.5 # the desired resolution of the grid to map to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297da7e4-efcf-4079-84f9-a0e45bd991c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44127, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>duplicate_id</th>\n",
       "      <th>title</th>\n",
       "      <th>word</th>\n",
       "      <th>spans</th>\n",
       "      <th>country_predicted</th>\n",
       "      <th>country_conf</th>\n",
       "      <th>admin1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>country_code3</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>place_name</th>\n",
       "      <th>feature_class</th>\n",
       "      <th>feature_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>369746</td>\n",
       "      <td>1997.4164</td>\n",
       "      <td>Study on multi-function ocean thermal energy c...</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>[{'start': 783, 'end': 787}]</td>\n",
       "      <td>FJI</td>\n",
       "      <td>0.946707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.0000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>FJI</td>\n",
       "      <td>2205218</td>\n",
       "      <td>Republic of Fiji</td>\n",
       "      <td>A</td>\n",
       "      <td>PCLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369760</td>\n",
       "      <td>1997.4175</td>\n",
       "      <td>Role of sewage phosphorus in coastal water ene...</td>\n",
       "      <td>Tuticorin</td>\n",
       "      <td>[{'start': 133, 'end': 142}]</td>\n",
       "      <td>IND</td>\n",
       "      <td>0.952811</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>8.8375</td>\n",
       "      <td>77.963</td>\n",
       "      <td>IND</td>\n",
       "      <td>7627069</td>\n",
       "      <td>Thoothukkudi</td>\n",
       "      <td>A</td>\n",
       "      <td>ADM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_id duplicate_id  \\\n",
       "0       369746    1997.4164   \n",
       "1       369760    1997.4175   \n",
       "\n",
       "                                               title       word  \\\n",
       "0  Study on multi-function ocean thermal energy c...       Fiji   \n",
       "1  Role of sewage phosphorus in coastal water ene...  Tuticorin   \n",
       "\n",
       "                          spans country_predicted  country_conf      admin1  \\\n",
       "0  [{'start': 783, 'end': 787}]               FJI      0.946707         NaN   \n",
       "1  [{'start': 133, 'end': 142}]               IND      0.952811  Tamil Nadu   \n",
       "\n",
       "       lat      lon country_code3  geonameid        place_name feature_class  \\\n",
       "0 -18.0000  178.000           FJI    2205218  Republic of Fiji             A   \n",
       "1   8.8375   77.963           IND    7627069      Thoothukkudi             A   \n",
       "\n",
       "  feature_code  \n",
       "0         PCLI  \n",
       "1         ADM2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in geoparsed location data\n",
    "\n",
    "# Set the directory path where your CSV files are located\n",
    "directory_path = '/home/dveytia/test-mordecai/outputs/geoparsed-text'\n",
    "dfs = [] # initialise empty list\n",
    "\n",
    "# Loop through all files in the directory and load\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # Read each CSV file into a DataFrame and append it to the list\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one\n",
    "places = pd.concat(dfs, ignore_index=True)\n",
    "places = places.drop_duplicates([\"id\",\"geonameid\"]) \n",
    "places = places.rename(columns={\"id\": \"analysis_id\"})\n",
    "print(places.shape)\n",
    "places.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90560576-f9ef-48fd-b8cd-c13c65eb4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you want to by-pass the next sections, load outputs directly:\n",
    "grid_df = pd.read_csv(f'/home/dveytia/test-mordecai/outputs/grid_df_res{gridRes}.csv', low_memory=False) # the grid\n",
    "shp_df = pd.read_csv(f'/home/dveytia/test-mordecai/outputs/shp_df_natural-earth-shapes.csv', low_memory=False) # natural earth shapefiles\n",
    "shp_grid_df = pd.read_csv(f'/home/dveytia/test-mordecai/outputs/shp_grid_df.csv', low_memory=False) # shapefiles matched to grid\n",
    "shp_df_matches = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_shp_df_matches.csv\", low_memory=False) # text match to shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c042d0d-c08e-4b71-b825-a72c52e70fd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set up grid to map to\n",
    "\n",
    "In this section, set up a grid to map to based on the desired resolution, calculate the area of each grid cell, and also determine if a grid cell is on land or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebfad472-6ba8-4edf-9d02-7c5158eda582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LAT     LON  grid_df_id\n",
      "0 -88.75 -178.75           0\n",
      "1 -88.75 -176.25           1\n",
      "2 -88.75 -173.75           2\n",
      "(10368, 3)\n"
     ]
    }
   ],
   "source": [
    "## Generate grid to map to\n",
    "def generate_grid_df(degrees):\n",
    "    '''\n",
    "    Generate a dataframe with a grid of of cells degrees x degrees\n",
    "    '''\n",
    "    LON = np.linspace(-180+degrees*0.5,180-degrees*0.5,int(360/degrees))\n",
    "    LAT = np.linspace(-90+degrees*0.5,90-degrees*0.5,int(180/degrees))\n",
    "    lon_df, lat_df = np.meshgrid(LON,LAT)\n",
    "\n",
    "    return pd.DataFrame({\"LAT\": lat_df.ravel(), \"LON\": lon_df.ravel()})\n",
    "    \n",
    "grid_df = generate_grid_df(gridRes)\n",
    "\n",
    "grid_df['grid_df_id'] = range(len(grid_df))\n",
    "\n",
    "print(grid_df.head(3))\n",
    "print(grid_df.shape) # (10368, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5c62aa-1256-4383-95ce-ce1eaf984f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate area of each grid cell\n",
    "\n",
    "# Define function to calculate the area of a gridcell given the center lat and lon and the size in degrees\n",
    "import math\n",
    "def area_cell(lat, lon, degrees): \n",
    "    # calculate the area of a gridcell given the center lat and lon and the size in degrees\n",
    "    if lon <0:\n",
    "        lon+=360\n",
    "    R = 6371\n",
    "    f0 = math.radians(lat-degrees*0.5)\n",
    "    f1 = math.radians(lat+degrees*0.5)\n",
    "    l0 = math.radians(lon-degrees*0.5)\n",
    "    l1 = math.radians(lon+degrees*0.5)\n",
    "\n",
    "    return (math.sin(f1)-math.sin(f0)) * (l1 - l0) * R**2\n",
    "\n",
    "# Calculate area of each grid cell\n",
    "grid_df['area_km'] = grid_df.apply(lambda x: area_cell(x['LAT'], x['LON'], gridRes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ea8da0-aa3b-4b4e-a8ea-d688332e3449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>grid_df_id</th>\n",
       "      <th>area_km</th>\n",
       "      <th>is_land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-178.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-173.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-171.25</td>\n",
       "      <td>3</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-168.75</td>\n",
       "      <td>4</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LAT     LON  grid_df_id      area_km  is_land\n",
       "0 -88.75 -178.75           0  1685.654015    False\n",
       "1 -88.75 -176.25           1  1685.654015    False\n",
       "2 -88.75 -173.75           2  1685.654015    False\n",
       "3 -88.75 -171.25           3  1685.654015    False\n",
       "4 -88.75 -168.75           4  1685.654015    False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine which grid cells are on land\n",
    "\n",
    "# Create a list to determine if a cell is on land\n",
    "land_masks = []\n",
    "n = 5\n",
    "land_array = np.empty((grid_df.shape[0], n*n))\n",
    "i = 0\n",
    "for x in np.linspace(0,2.5,n):\n",
    "    for y in np.linspace(0,2.5,n):\n",
    "        land_array[:,i] = globe.is_land(grid_df.LAT+y-1.25, grid_df.LON+x-1.25)\n",
    "        i+=1\n",
    "        \n",
    "land_mask = land_array.sum(axis=1)>0\n",
    "\n",
    "# Add a column indicating if the grid cell is on land\n",
    "grid_df['is_land'] = land_mask\n",
    "grid_df.loc[grid_df['LAT']<-60,'is_land'] = False\n",
    "\n",
    "# Print how many cells are on land -- 3311\n",
    "grid_df.is_land.sum() \n",
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be44bed5-0253-41e7-81a8-4ecb38f20e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export grid to reference file\n",
    "grid_df.to_csv(f'/home/dveytia/test-mordecai/outputs/grid_df_res{gridRes}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85acaa35-2f05-421b-98f4-110ffcd2540a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read in shapefiles from Natural Earth\n",
    "\n",
    "Create a lookup table for each natural earth shape file and grid cell. Read in shapefiles from Natural Earth, and based on the grid, and determine which grid cells correspond to which shape files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e3b75b7-ad69-4f65-9abf-382980c4e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading shapefile {'resolution': '50m', 'category': 'cultural', 'name': 'admin_0_countries'}\n",
      "reading shapefile {'resolution': '10m', 'category': 'cultural', 'name': 'admin_1_states_provinces'}\n",
      "reading shapefile {'resolution': '10m', 'category': 'physical', 'name': 'geography_regions_polys'}\n",
      "reading shapefile {'resolution': '10m', 'category': 'physical', 'name': 'geography_marine_polys'}\n"
     ]
    }
   ],
   "source": [
    "## Read in shapefiles from natural earth\n",
    "# First we define a list of the shapefile definitions we want\n",
    "shpfiles = [\n",
    "    dict(resolution='50m', category='cultural', name='admin_0_countries'),\n",
    "    dict(resolution='10m', category='cultural', name='admin_1_states_provinces'),\n",
    "    dict(resolution='10m', category='physical', name='geography_regions_polys'),\n",
    "    dict(resolution='10m', category='physical', name='geography_marine_polys')\n",
    "    #\"data/gadm36_1.shp\"\n",
    "]\n",
    "\n",
    "# We'll start an empty dataframe to store our shapefile-grid matches\n",
    "shp_grid_df = pd.DataFrame()\n",
    "\n",
    "# Now we download the shapefiles and combine into one large geopandas dataframe\n",
    "shp_df  = None\n",
    "for shpfilename in shpfiles:\n",
    "    print(f\"reading shapefile {shpfilename}\")\n",
    "    if shp_df is None:\n",
    "        shp_df = geopandas.read_file(shpreader.natural_earth(**shpfilename))\n",
    "    else:\n",
    "        shp_df = pd.concat([shp_df, geopandas.read_file(shpreader.natural_earth(**shpfilename))])\n",
    "        #shp_df = shp_df.merge(geopandas.read_file(shpreader.natural_earth(**shpfilename)),how=\"outer\")\n",
    "    time.sleep(10) # Wait a bit before downloading the next shapefile so we do not make too many requests too quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97bd20a9-e90a-4e76-992a-c73c551b77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6191, 264)\n",
      "        featurecla  scalerank  LABELRANK SOVEREIGNT SOV_A3  ADM0_DIF  LEVEL  \\\n",
      "0  Admin-0 country        1.0        3.0   Zimbabwe    ZWE       0.0    2.0   \n",
      "1  Admin-0 country        1.0        3.0     Zambia    ZMB       0.0    2.0   \n",
      "\n",
      "                TYPE TLC     ADMIN  ... name_zht  FEATURECLA NAMEALT REGION  \\\n",
      "0  Sovereign country   1  Zimbabwe  ...      NaN         NaN     NaN    NaN   \n",
      "1  Sovereign country   1    Zambia  ...      NaN         NaN     NaN    NaN   \n",
      "\n",
      "   SCALERANK LABEL namealt  changed label shpfile_id  \n",
      "0        NaN   NaN     NaN      NaN   NaN          0  \n",
      "1        NaN   NaN     NaN      NaN   NaN          1  \n",
      "\n",
      "[2 rows x 264 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mordecai_env_3.8/lib/python3.8/site-packages/geopandas/geodataframe.py:1538: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "shp_df['shpfile_id'] = range(len(shp_df))\n",
    "print(shp_df.shape)\n",
    "print(shp_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae48e440-4c4a-47e6-bf43-fbe9a30a4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.191000e+03\n",
       "mean     1.738410e+05\n",
       "std      2.007239e+06\n",
       "min      1.007477e-06\n",
       "25%      6.902486e+02\n",
       "50%      5.102613e+03\n",
       "75%      2.997981e+04\n",
       "max      8.010105e+07\n",
       "Name: area_km2, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate area of each polygon in km2\n",
    "from pyproj import Geod\n",
    "from shapely import wkt\n",
    "\n",
    "def area_poly(poly): \n",
    "    # specify a named ellipsoid\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "    # calculate area\n",
    "    return abs(geod.geometry_area_perimeter(poly)[0])/1000000\n",
    "\n",
    "\n",
    "shp_df['area_km2'] = shp_df.apply(lambda x: area_poly(x['geometry']), axis=1)\n",
    "\n",
    "## NB if I want to check, here is a quick way to plot the polygon\n",
    "# import matplotlib.pyplot as plt\n",
    "# poly = shp_df['geometry'].iloc[0]\n",
    "# plt.plot(*poly.exterior.xy)\n",
    "\n",
    "shp_df['area_km2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71fbb93d-7a75-40da-9e78-88dcbea79cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save natural earth shapefiles\n",
    "shp_df.to_csv(f'/home/dveytia/test-mordecai/outputs/shp_df_natural-earth-shapes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c36fbbb-467a-44ec-98ac-d605da624b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shpfile_id</th>\n",
       "      <th>grid_df_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shpfile_id  grid_df_id\n",
       "0           0        4114\n",
       "1           0        3971"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Match shapefiles to gridcell indices \n",
    "\n",
    "# We are going to store our shapefile-gridcell index matches here\n",
    "shp_grid = []\n",
    "\n",
    "# This is the grid we will work with\n",
    "yv, xv = np.meshgrid(grid_df.LAT.unique(), grid_df.LON.unique())\n",
    "for i, place in shp_df.iterrows(): # Now we go through all the shapes\n",
    "    # show which gridcell centers are contained inside the shape\n",
    "    # ignore the warning caused by shapely using an old version of numpy\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        inplace = shapely.vectorized.contains(place.geometry, xv, yv)\n",
    "    idx = np.argwhere(inplace)\n",
    "    # Get the number of cells contained in the shape\n",
    "    number_cells = idx.size/2\n",
    "    if number_cells == 0:\n",
    "        # If we have no cell centers in the shape, get the shape center and the cell which contains it\n",
    "        c = place.geometry.centroid\n",
    "        lon = c.x//gridRes*gridRes+gridRes*0.5\n",
    "        lat = c.y//gridRes*gridRes+gridRes*0.5\n",
    "        da_df = grid_df[(grid_df['LON']==lon) & (grid_df['LAT']==lat)]\n",
    "        shp_grid.append({\"shpfile_id\": i, \"grid_df_id\": da_df.index[0]})\n",
    "    else:\n",
    "        for point in idx:\n",
    "            lon = grid_df.LON.unique()[point[0]]\n",
    "            lat = grid_df.LAT.unique()[point[1]]\n",
    "            da_df = grid_df[(grid_df['LON']==lon) & (grid_df['LAT']==lat)]\n",
    "            shp_grid.append({\"shpfile_id\": i, \"grid_df_id\": da_df.index[0]}) \n",
    "\n",
    "shp_grid_df = pd.DataFrame.from_dict(shp_grid)\n",
    "    \n",
    "\n",
    "shp_grid_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c06c0b62-1b49-4456-ad3f-c60a600c3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_grid_df.to_csv(f'/home/dveytia/test-mordecai/outputs/shp_grid_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a26fd-b67e-41c7-96d8-276585f32365",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Document to grid matching\n",
    "\n",
    "Look for place matches between mordecai geoparsing results and the shape files, and then map these results to grid cells. Then sum the number of documents found in each grid cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50cf17c-7f81-4b00-aeba-859dc19b7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapping = {\n",
    "    \"ADM1\": [\"Admin-1 scale rank\", \"Admin-1 aggregation\", \"Admin-1 minor island\"],\n",
    "    \"PCLI\": [\"Admin-0 country\"],\n",
    "    'MTS': ['Range/mtn'],\n",
    "    'PLAT': ['Plateau'],\n",
    "    'PLN': ['Plain'],\n",
    "    'DSRT': ['Desert'],\n",
    "    'OCN': ['ocean'],\n",
    "    'SEA': ['sea', 'bay'],\n",
    "    'GULF': ['gulf', 'bay'],\n",
    "    'BAY': ['gulf', 'bay'],\n",
    "    'CHN': ['channel'],\n",
    "    'BSNU': ['basin']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d333d32-e4cd-4418-a5c2-66a154346323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add all the other codes we don't cover with blank shapefile classes\n",
    "for fcode in places.feature_code.unique():\n",
    "    if fcode not in feature_mapping:\n",
    "        feature_mapping[fcode] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e40039a-7f6f-43c9-8000-e03435b9f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3362076/2263670162.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  places[\"place_name\"] = places[\"place_name\"].str.lower().str.replace(\"mts.\",\"mountains\")\n",
      "/tmp/ipykernel_3362076/2263670162.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  shp_df[\"name\"] = shp_df[\"name\"].str.lower().str.replace(\"mts.\",\"mountains\")\n"
     ]
    }
   ],
   "source": [
    "# To help match, we will rename some shapes so that they are the same as the name in our database\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Altay\", case=False)),\"name\"] = \"Altay\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Appalach\", case=False)),\"name\"] = \"Appalachian Mountains\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"cant\", case=False)),\"name\"] = \"Cordillera Cantábrica\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Dabie\", case=False)),\"name\"] = \"Dabie Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"EASTERN GHATS\", case=False)),\"name\"] = \"Eastern Ghāts\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"WESTERN GHATS\", case=False)),\"name\"] = \"Western Ghāts\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"kunlun\", case=False)),\"name\"] = \"Kalakunlun Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"LEN MOUNTAIN\", case=False)),\"name\"] = \"Kölen\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Taihang Mts.\", case=False)),\"name\"] = \"Taihang Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Tatra Mts.\", case=False)),\"name\"] = \"Tatry\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"TIAN SHAN\", case=False)),\"name\"] = \"Tien Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"andes\", case=False)),\"name\"] = \"Andes Mountains\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"HINDU KUSH\", case=False)),\"name\"] = \"Hindū Kush\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Marrah Mts\", case=False)),\"name\"] = \"Jabal Marrah\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Lebanon\", case=False)),\"name\"] = \"Mount Lebanon\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"KARAKORAM RA\", case=False)),\"name\"] = \"Karakorum Shan\"\n",
    "\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"Negev\", case=False)), \"name\"] = \"Negev\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"Atacama\", case=False)), \"name\"] = \"Atacama Desert\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"CHIHUAHUAN DESERT\", case=False)), \"name\"] = \"Chihuahua Desert\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"Lut desert\", case=False)), \"name\"] = \"God-e Lut\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"TAKLIMAKAN DESERT\", case=False)), \"name\"] = \"Takla Makan Desert\"\n",
    "\n",
    "shp_df.loc[\n",
    "    (shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"cumberland\", case=False)),[\"name\",\"featurecla\"]\n",
    "] = [\"Cumberland Plateau\", \"Plain\"]\n",
    "shp_df.loc[\n",
    "    (shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"colorado\", case=False)),[\"name\",\"featurecla\"]\n",
    "] = [\"San Francisco Plateau\", \"Plain\"]\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plain\") & (shp_df[\"name\"].str.contains(\"gange\", case=False)),\"name\"] = \"Gangetic Plain\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plain\") & (shp_df[\"name\"].str.contains(\"north china\", case=False)),\"name\"] = \"Huanghuai Pingyuan\"\n",
    "\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"mongol\", case=False)), \"name\"] = \"Nei Mongol Gaoyuan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"deccan\", case=False)), \"name\"] = \"Deccan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"chota\", case=False)), \"name\"] = \"Chota Nāgpur Plateau\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"loess\", case=False)), \"name\"] = \"Huangtu Gaoyuan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"khorat\", case=False)), \"name\"] = \"Khorat Plateau\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"tibet\", case=False)), \"name\"] = \"Qing Zang Gaoyuan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"polar\", case=False)), \"name\"] = \"South Polar Plateau\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"YUNGUI\", case=False)), \"name\"] = \"Yungui Gaoyuan\"\n",
    "\n",
    "places[\"place_name\"] = places[\"place_name\"].str.lower().str.replace(\"mts.\",\"mountains\") \n",
    "shp_df[\"name\"] = shp_df[\"name\"].str.lower().str.replace(\"mts.\",\"mountains\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0489f-cbf4-4f47-91fd-6685348ec803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(944534, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_df_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>shp_id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>6095</td>\n",
       "      <td>284452.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>antigua and barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>7568</td>\n",
       "      <td>284452.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>antigua and barbuda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      grid_df_id  analysis_id  shp_id                place\n",
       "2488        6095     284452.0   232.0  antigua and barbuda\n",
       "3895        7568     284452.0   232.0  antigua and barbuda"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NB this takes several min to run\n",
    "## For each document that has a place, search for a match from the natural earth shapefiles and it's corresponding grid cell indexes\n",
    "## Reminder the object 'places' is a data frame that contains all the document information with places identified\n",
    "\n",
    "# We'll start off with an empty dataframe\n",
    "shp_df_matches = pd.DataFrame()\n",
    "\n",
    "# Now we want to look through the feature type dictionary we had before\n",
    "for place_key, shpfile_keys in feature_mapping.items():\n",
    "    \n",
    "    #print(place_key)\n",
    "    \n",
    "    # We can get all the places and all the shapes\n",
    "    feature_places = places.loc[places[\"feature_code\"]==place_key]\n",
    "    feature_shapes = shp_df.loc[shp_df[\"featurecla\"].isin(shpfile_keys)]\n",
    "    \n",
    "    # And loop through the places\n",
    "    for place, group in feature_places.groupby(\"place_name\"):\n",
    "        # If we don't have a shapefile feature type we just take the grid cell containing the point\n",
    "        if not shpfile_keys:\n",
    "            shp_id = None # we set shp_id to None, round the coordinates, and take the gridcell which has these coordinates\n",
    "            lon = group.lon.values[0]//gridRes*gridRes+gridRes*0.5\n",
    "            lat = group.lat.values[0]//gridRes*gridRes+gridRes*0.5\n",
    "            grid_df_ids = grid_df[(grid_df['LON']==lon) & (grid_df['LAT']==lat)].index\n",
    "\n",
    "        else:\n",
    "            # Otherwise, we are going to try to find the places which match\n",
    "            place_shapes = pd.DataFrame()\n",
    "            # First we will try by geoname ids, if we have these\n",
    "            if feature_shapes[\"gn_id\"].sum() > 0:\n",
    "                place_shapes = feature_shapes.loc[\n",
    "                    (feature_shapes[\"gn_id\"]==group.geonameid.values[0])\n",
    "                ]\n",
    "            # Then we try by country code, if we are dealing with a country\n",
    "            if place_shapes.shape[0]==0 and place_key==\"PCLI\":\n",
    "                place_shapes = feature_shapes.loc[\n",
    "                    feature_shapes[\"ADM0_A3\"] == group.country_predicted.values[0]\n",
    "                ]\n",
    "            # Then we try by name\n",
    "            if place_shapes.shape[0]==0:       \n",
    "                place_shapes = feature_shapes.loc[\n",
    "                    (feature_shapes.name == place)\n",
    "                ]    \n",
    "\n",
    "            if place_shapes.shape[0]==0:\n",
    "                continue # These are the places we cannot match, we need to develop other strategies for these, e.g. using other shapefile libraries\n",
    "    #            if key==\"ADM1\": # can also try using gadm data, which we need to download separately\n",
    "    #                 place_shapes = adm1shps_alt[\n",
    "    #                     (adm1shps_alt[\"NAME_1\"]==group.place_name.values[0]) |\n",
    "    #                     (adm1shps_alt[\"VARNAME_1\"].str.contains(group.place_name.values[0]))\n",
    "    #                 ]\n",
    "            else:\n",
    "                shp_id = place_shapes.index[0]\n",
    "                grid_df_ids = shp_grid_df.loc[\n",
    "                    (shp_grid_df[\"shpfile_id\"]==shp_id),\n",
    "                    \"grid_df_id\"\n",
    "                ]\n",
    "        # For each document with this place, we add a row for each grid cell index matching the place\n",
    "        for did in group.analysis_id.unique():\n",
    "            shp_df_matches = pd.concat([\n",
    "                shp_df_matches,\n",
    "                pd.DataFrame.from_dict({\n",
    "                    \"grid_df_id\": grid_df_ids,\n",
    "                    \"analysis_id\": [did] * len(grid_df_ids),\n",
    "                    \"shp_id\": [shp_id] * len(grid_df_ids),\n",
    "                    \"place\": place\n",
    "                })\n",
    "            ])\n",
    "            \n",
    "            \n",
    "print(shp_df_matches.shape)\n",
    "shp_df_matches.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ddb3470-fa8f-4c68-a921-4cda69b8a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(944534, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_df_id</th>\n",
       "      <th>analysis_id</th>\n",
       "      <th>shp_id</th>\n",
       "      <th>place</th>\n",
       "      <th>cell_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6095</td>\n",
       "      <td>284452.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>antigua and barbuda</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7568</td>\n",
       "      <td>284452.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>antigua and barbuda</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_df_id  analysis_id  shp_id                place  cell_weight\n",
       "0        6095     284452.0   232.0  antigua and barbuda         0.25\n",
       "1        7568     284452.0   232.0  antigua and barbuda         0.25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_df_matches = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_shp_df_matches.csv\", low_memory = False)\n",
    "\n",
    "## For each unique document and place, calculate the 1/the number of grid cells occupied by that place to get the grid cell weight\n",
    "shp_df_weight = shp_df_matches.groupby(['analysis_id','shp_id']).apply(lambda x: 1/len(x)).reset_index() # calculate 1/number of grid cells per place\n",
    "shp_df_weight = shp_df_weight.set_axis(['analysis_id','shp_id','cell_weight'], axis=1) # rename columns\n",
    "shp_df_matches = shp_df_matches.merge(shp_df_weight, how='left') # Merge back into the corresponding grid cells\n",
    "\n",
    "\n",
    "print(shp_df_matches.shape)\n",
    "shp_df_matches.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c856ec1-65e1-4a77-958c-651ba1de24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to csv\n",
    "shp_df_matches.to_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_shp_df_matches.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c90684e-b37f-4504-a2bb-109bf55ab665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>grid_df_id</th>\n",
       "      <th>area_km</th>\n",
       "      <th>is_land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-178.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-173.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-171.25</td>\n",
       "      <td>3</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-168.75</td>\n",
       "      <td>4</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LAT     LON  grid_df_id      area_km  is_land\n",
       "0 -88.75 -178.75           0  1685.654015    False\n",
       "1 -88.75 -176.25           1  1685.654015    False\n",
       "2 -88.75 -173.75           2  1685.654015    False\n",
       "3 -88.75 -171.25           3  1685.654015    False\n",
       "4 -88.75 -168.75           4  1685.654015    False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63801eb-6daf-44a0-b10a-18b1bcae6190",
   "metadata": {},
   "source": [
    "# Read in document to shpfile matches and sum number of matches per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc4e7f32-cead-4b82-a1f7-98971d00020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10368, 7)\n",
      "                LAT           LON   grid_df_id       area_km    n_articles  \\\n",
      "count  10368.000000  10368.000000  10368.00000  10368.000000  10368.000000   \n",
      "mean       0.000000      0.000000   5183.50000  49196.033170     91.100887   \n",
      "std       51.959018    103.925555   2993.12813  23773.819701    202.332822   \n",
      "min      -88.750000   -178.750000      0.00000   1685.654015      0.000000   \n",
      "25%      -44.375000    -89.375000   2591.75000  30341.895615      0.000000   \n",
      "50%        0.000000      0.000000   5183.50000  54625.716973     10.000000   \n",
      "75%       44.375000     89.375000   7775.25000  71049.402794     54.000000   \n",
      "max       88.750000    178.750000  10367.00000  77252.429797   2637.000000   \n",
      "\n",
      "       n_articles_weighted  \n",
      "count         10368.000000  \n",
      "mean              1.412519  \n",
      "std               9.221334  \n",
      "min               0.000000  \n",
      "25%               0.000000  \n",
      "50%               0.009322  \n",
      "75%               0.220820  \n",
      "max             295.271429  \n",
      "     LAT     LON  grid_df_id      area_km  is_land  n_articles  \\\n",
      "0 -88.75 -178.75           0  1685.654015    False         0.0   \n",
      "1 -88.75 -176.25           1  1685.654015    False         0.0   \n",
      "2 -88.75 -173.75           2  1685.654015    False         0.0   \n",
      "3 -88.75 -171.25           3  1685.654015    False         0.0   \n",
      "4 -88.75 -168.75           4  1685.654015    False         0.0   \n",
      "\n",
      "   n_articles_weighted  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n"
     ]
    }
   ],
   "source": [
    "## Read in \n",
    "shp_df_matches = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_shp_df_matches.csv\", low_memory = False)\n",
    "\n",
    "## For each grid cell, sum the number of documents \n",
    "shp_df_sum = shp_df_matches.groupby(['grid_df_id']).apply(lambda x: len(x)).reset_index()\n",
    "shp_df_sum = shp_df_sum.set_axis(['grid_df_id','n_articles'], axis=1)\n",
    "\n",
    "## For each grid cell, sum the weighted number of documents to get the weighted sum\n",
    "shp_df_weightedSum = shp_df_matches.groupby(['grid_df_id'])['cell_weight'].sum().reset_index()\n",
    "shp_df_weightedSum = shp_df_weightedSum.set_axis(['grid_df_id','n_articles_weighted'], axis=1)\n",
    "\n",
    "\n",
    "## Merge all together with the grid cell locations \n",
    "# Format the grid so the id column is identiical to allow for a merge\n",
    "grid_df2 = grid_df\n",
    "grid_df2['grid_df_id'] = grid_df.index\n",
    "\n",
    "# Merge\n",
    "shp_df_sum_grid = grid_df2.merge(shp_df_sum, how = \"left\")\n",
    "shp_df_sum_grid = shp_df_sum_grid.merge(shp_df_weightedSum, how = \"left\")\n",
    "\n",
    "# Summarise\n",
    "shp_df_sum_grid['n_articles'] = shp_df_sum_grid['n_articles'].fillna(0) # set NAs to 0\n",
    "shp_df_sum_grid['n_articles_weighted'] = shp_df_sum_grid['n_articles_weighted'].fillna(0) # set NAs to 0\n",
    "print(shp_df_sum_grid.shape)\n",
    "print(shp_df_sum_grid.describe())\n",
    "print(shp_df_sum_grid.head())\n",
    "\n",
    "# Save\n",
    "shp_df_sum_grid.to_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_grid-sums.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e7609-f5ee-4371-9e0f-6ccbba9e6bfd",
   "metadata": {},
   "source": [
    "## Simple map to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56106d8-aaee-41eb-a10c-298a4d82ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of all articles using the weighted sum\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colormaps\n",
    "import matplotlib as mpl\n",
    "    \n",
    "# Read in the data    \n",
    "shp_df_sum_grid = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_grid-sums.csv\")\n",
    "gridlons = shp_df_sum_grid.LON.unique()\n",
    "gridlats = shp_df_sum_grid.LAT.unique()\n",
    "shape = (len(gridlats), len(gridlons))\n",
    "n = np.array(shp_df_sum_grid.n_articles_weighted).reshape(shape)\n",
    "\n",
    "# quick check\n",
    "plt.imshow(n, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# set up a map\n",
    "fig=plt.figure()\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "\n",
    "# Can use the regular grid lons and lats with the shading ='nearest' option\n",
    "im = plt.pcolormesh(gridlons, gridlats, n, shading = 'nearest',\n",
    "              cmap=colormaps['magma_r'], norm=mpl.colors.LogNorm(), transform=ccrs.PlateCarree()) \n",
    "\n",
    "ax.coastlines()\n",
    "\n",
    "## Colourbar\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "cbar = plt.colorbar(im, cax=cax) \n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "cbar.set_label('Weighted # of articles', rotation=270)\n",
    "\n",
    "# Save\n",
    "plt.savefig(f'/home/dveytia/test-mordecai/figures/geoparsed-text-map.pdf',bbox_inches=\"tight\") # Save plot, change file path and name\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf72db7-1700-4e97-908d-c77fb89b6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of all articles in the ocean only using the weighted sum\n",
    "\n",
    "# Read in the data    \n",
    "shp_df_sum_grid = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_grid-sums.csv\")\n",
    "\n",
    "# Set everything on land to 0\n",
    "shp_df_sum_grid_ocean = shp_df_sum_grid\n",
    "shp_df_sum_grid_ocean.loc[shp_df_sum_grid_ocean['is_land'] == True, 'n_articles_weighted'] = 0\n",
    "\n",
    "# Format into grid\n",
    "gridlons = shp_df_sum_grid_ocean.LON.unique()\n",
    "gridlats = shp_df_sum_grid_ocean.LAT.unique()\n",
    "shape = (len(gridlats), len(gridlons))\n",
    "n = np.array(shp_df_sum_grid_ocean.n_articles_weighted).reshape(shape)\n",
    "\n",
    "# set up a map\n",
    "fig=plt.figure()\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "\n",
    "# Can use the regular grid lons and lats with the shading ='nearest' option\n",
    "im = plt.pcolormesh(gridlons, gridlats, n, shading = 'nearest',\n",
    "              cmap=colormaps['magma_r'], norm=mpl.colors.LogNorm(), transform=ccrs.PlateCarree()) \n",
    "\n",
    "ax.coastlines()\n",
    "\n",
    "## Colourbar\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "cbar = plt.colorbar(im, cax=cax) \n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "cbar.set_label('Weighted # of articles', rotation=270)\n",
    "\n",
    "# Save\n",
    "plt.savefig(f'/home/dveytia/test-mordecai/figures/geoparsed-text-ocean-map.pdf',bbox_inches=\"tight\") # Save plot, change file path and name\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a0ef9-21f4-48e0-9264-aefe8c1d7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colormaps\n",
    "\n",
    "## read in dataframe of grid matches\n",
    "shp_df_sum_grid = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_grid-sums.csv\")\n",
    "\n",
    "## Plot\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = fig.add_subplot(projection=ccrs.Robinson())\n",
    "ax.coastlines(lw=0.2)\n",
    "\n",
    "\n",
    "shape = (len(shp_df_sum_grid.LAT.unique()), len(shp_df_sum_grid.LON.unique()))\n",
    "n = np.array(shp_df_sum_grid.n_articles).reshape(shape)\n",
    "mesh=ax.pcolormesh(\n",
    "    shp_df_sum_grid.LON.unique(), \n",
    "    shp_df_sum_grid.LAT.unique(), \n",
    "    n, \n",
    "    cmap=colormaps['magma_r'],\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325341b-bbb9-4bbd-84c3-0002cc1911ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10368, 4)\n",
      "                LAT           LON   grid_df_id    n_articles\n",
      "count  10368.000000  10368.000000  10368.00000  10368.000000\n",
      "mean       0.000000      0.000000   5183.50000     91.100887\n",
      "std       51.959018    103.925555   2993.12813    202.332822\n",
      "min      -88.750000   -178.750000      0.00000      0.000000\n",
      "25%      -44.375000    -89.375000   2591.75000      0.000000\n",
      "50%        0.000000      0.000000   5183.50000     10.000000\n",
      "75%       44.375000     89.375000   7775.25000     54.000000\n",
      "max       88.750000    178.750000  10367.00000   2637.000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m shp_df_sum_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m z \u001b[38;5;241m=\u001b[39m shp_df_sum_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_articles\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpcolormesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGreens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(c)\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib.pyplot.pcolormesh() function Example\u001b[39m\u001b[38;5;124m'\u001b[39m, fontweight \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py:2773\u001b[0m, in \u001b[0;36mpcolormesh\u001b[0;34m(alpha, norm, cmap, vmin, vmax, shading, antialiased, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mpcolormesh)\n\u001b[1;32m   2769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpcolormesh\u001b[39m(\n\u001b[1;32m   2770\u001b[0m         \u001b[38;5;241m*\u001b[39margs, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2771\u001b[0m         vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, antialiased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2772\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2773\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpcolormesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2774\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshading\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialiased\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialiased\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2776\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2777\u001b[0m     sci(__ret)\n\u001b[1;32m   2778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mordecai_env_3.8/lib/python3.8/site-packages/cartopy/mpl/geoaxes.py:318\u001b[0m, in \u001b[0;36m_add_transform.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid transform: Spherical \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    314\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not supported - consider using \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    315\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlateCarree/RotatedPole.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    317\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mordecai_env_3.8/lib/python3.8/site-packages/cartopy/mpl/geoaxes.py:1785\u001b[0m, in \u001b[0;36mGeoAxes.pcolormesh\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# Add in an argument checker to handle Matplotlib's potential\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;66;03m# interpolation when coordinate wraps are involved\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_args(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1785\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpcolormesh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# Wrap the quadrilaterals if necessary\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_quadmesh(result, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1449\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1450\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py:6218\u001b[0m, in \u001b[0;36mAxes.pcolormesh\u001b[0;34m(self, alpha, norm, cmap, vmin, vmax, shading, antialiased, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6215\u001b[0m shading \u001b[38;5;241m=\u001b[39m shading\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   6216\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgecolors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 6218\u001b[0m X, Y, C, shading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pcolorargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcolormesh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6219\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mshading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshading\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6220\u001b[0m coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([X, Y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   6221\u001b[0m \u001b[38;5;66;03m# convert to one dimensional array, except for 3D RGB(A) arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_axes.py:5725\u001b[0m, in \u001b[0;36mAxes._pcolorargs\u001b[0;34m(self, funcname, shading, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5723\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Y, np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m   5724\u001b[0m             Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m-> 5725\u001b[0m     nrows, ncols \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   5726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _api\u001b[38;5;241m.\u001b[39mnargs_error(funcname, takes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 or 3\u001b[39m\u001b[38;5;124m\"\u001b[39m, given\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(args))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colormaps\n",
    "\n",
    "## read in dataframe of grid matches\n",
    "shp_df_sum_grid = pd.read_csv(\"/home/dveytia/test-mordecai/outputs/geoparsed-text_grid-sums.csv\")\n",
    "print(shp_df_sum_grid.shape)\n",
    "print(shp_df_sum_grid.describe())\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = fig.add_subplot(projection=ccrs.Robinson())\n",
    "ax.coastlines(lw=0.2)\n",
    "\n",
    "x = shp_df_sum_grid['LON']\n",
    "y = shp_df_sum_grid['LAT']\n",
    "z = shp_df_sum_grid['n_articles']\n",
    "\n",
    "\n",
    "c = plt.pcolormesh(x, y, z, cmap ='Greens')\n",
    "plt.colorbar(c)\n",
    " \n",
    "plt.title('matplotlib.pyplot.pcolormesh() function Example', fontweight =\"bold\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf82e1-6504-4d34-a7d8-eef7ed01608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (len(shp_df_sum_grid.LAT.unique()), len(shp_df_sum_grid.LON.unique()))\n",
    "n = np.array(shp_df_sum_grid.n_articles).reshape(shape)\n",
    "mesh=ax.pcolormesh(\n",
    "    shp_df_sum_grid.LON.unique(), \n",
    "    shp_df_sum_grid.LAT.unique(), \n",
    "    n, \n",
    "    cmap=colormaps['magma_r'],\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mordecai_gridding",
   "language": "python",
   "name": "mordecai_gridding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
